{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Yelp review data\n",
    "yelp_path = 'textdata/yelp_labelled.txt'\n",
    "yelp_raw = pd.read_csv(yelp_path, delimiter='\\t', header=None)\n",
    "yelp_raw.columns = ['review', 'positive']\n",
    "\n",
    "# Create train and test data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(yelp_raw['review'], yelp_raw['positive'], test_size = 0.2, random_state=20)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model tests 22 words that I believe would be indicative of a positive or negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify words\n",
    "words = ['good', 'great', 'bad', 'awful', 'not', 'angry', 'happy', 'glad', 'thrilled', 'sucks', 'recommend', 'wow', 'love', 'hate', 'nasty', 'service', 'food', 'atmosphere', 'loud', 'delicious', 'tasty', 'gross']\n",
    "\n",
    "# Create dummies indicating if a review contains a specified word\n",
    "for word in words:\n",
    "    X_train[str(word)] = X_train['review'].str.contains(str(word), case=False)\n",
    "    X_test[str(word)] = X_test['review'].str.contains(str(word), case=False)\n",
    "\n",
    "# Create function printing results of a model's prediction\n",
    "def print_results(y_test, y_pred, y_train, y_train_pred):\n",
    "    \n",
    "    # Compute measurements for test data\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = (y_test == y_pred).sum()/len(y_test)\n",
    "    \n",
    "    # Computer measurements for training data\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    accuracy_train = (y_train == y_train_pred).sum()/len(y_train)\n",
    "    \n",
    "    # Print Accuracy and associated meaasurements for training data\n",
    "    print('---------------     Results     ---------------\\n')\n",
    "    print('---------------  Training Data  ---------------\\n')\n",
    "    print('Accuracy: \\t{}%'.format(round(accuracy_train*100,1)))\n",
    "    print('Sensitivity: \\t{}%'.format(round(cm_train[1][1]*100/sum(cm_train[1]),1)))\n",
    "    print('Specificity: \\t{}%\\n'.format(round(cm_train[0][0]*100/sum(cm_train[0]),1)))\n",
    "    \n",
    "    # Print Accuracy and associated meaasurements for test sample predictions\n",
    "    print('---------------   Out of Sample ---------------\\n')\n",
    "    print('Accuracy: \\t{}%'.format(round(accuracy*100,1)))\n",
    "    print('Sensitivity: \\t{}%'.format(round(cm[1][1]*100/sum(cm[1]),1)))\n",
    "    print('Specificity: \\t{}%'.format(round(cm[0][0]*100/sum(cm[0]),1)))\n",
    "    \n",
    "    # Print confusion matrix for test sample predictions\n",
    "    print('\\n----------------Confusion Matrix---------------\\n')\n",
    "    print('                      Predicted Value')\n",
    "    print('\\t\\t |  Positive | Negative  |')\n",
    "    print('\\t\\t  -----------------------')\n",
    "    print('Actual \\t|Positive|\\t{}   |    {}\\t |'.format(cm[0][0], cm[0][1]))\n",
    "    print('Value    --------------------------------')\n",
    "    print('\\t|Negative|\\t{}   |    {}\\t |'.format(cm[1][0], cm[1][1]))\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------     Results     ---------------\n",
      "\n",
      "---------------  Training Data  ---------------\n",
      "\n",
      "Accuracy: \t66.5%\n",
      "Sensitivity: \t43.8%\n",
      "Specificity: \t89.4%\n",
      "\n",
      "---------------   Out of Sample ---------------\n",
      "\n",
      "Accuracy: \t71.0%\n",
      "Sensitivity: \t48.0%\n",
      "Specificity: \t93.1%\n",
      "\n",
      "----------------Confusion Matrix---------------\n",
      "\n",
      "                      Predicted Value\n",
      "\t\t |  Positive | Negative  |\n",
      "\t\t  -----------------------\n",
      "Actual \t|Positive|\t95   |    7\t |\n",
      "Value    --------------------------------\n",
      "\t|Negative|\t51   |    47\t |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Compute parameter estimates with training data\n",
    "bnb.fit(X_train[words], y_train)\n",
    "\n",
    "# Predict target values for our test data\n",
    "y_pred = bnb.predict(X_test[words])\n",
    "\n",
    "# Predict target values with data the model was trained on\n",
    "y_pred_train = bnb.predict(X_train[words])\n",
    "\n",
    "# Print results\n",
    "print_results(y_test, y_pred, y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model is accurate 71% of the time on a test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all (cleaned) words in the training data\n",
    "\n",
    "allwords = []\n",
    "\n",
    "for review in X_train.review:\n",
    "    review = review.lower()\n",
    "    review = review.replace('.','').replace('!','').replace(',','').replace('?','').replace(':','').replace(';','')\n",
    "    review = review.replace('\"','').replace(\"'\",'').replace('-','').replace('(','').replace(')','').replace('&','and')\n",
    "    review = review.replace('$','').replace(\"%\",'').replace('*','').replace('+','').replace('/','')\n",
    "    allwords += review.split()\n",
    "\n",
    "# Create list of 100 most common words in the data set\n",
    "commonwords = list(pd.Series(allwords).value_counts().index[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next model uses the 100 most common words in our sample as factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------     Results     ---------------\n",
      "\n",
      "---------------  Training Data  ---------------\n",
      "\n",
      "Accuracy: \t75.2%\n",
      "Sensitivity: \t78.1%\n",
      "Specificity: \t72.4%\n",
      "\n",
      "---------------   Out of Sample ---------------\n",
      "\n",
      "Accuracy: \t66.5%\n",
      "Sensitivity: \t71.4%\n",
      "Specificity: \t61.8%\n",
      "\n",
      "----------------Confusion Matrix---------------\n",
      "\n",
      "                      Predicted Value\n",
      "\t\t |  Positive | Negative  |\n",
      "\t\t  -----------------------\n",
      "Actual \t|Positive|\t63   |    39\t |\n",
      "Value    --------------------------------\n",
      "\t|Negative|\t28   |    70\t |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove factors from previous model\n",
    "X_train = pd.DataFrame(X_train['review'])\n",
    "X_test = pd.DataFrame(X_test['review'])\n",
    "\n",
    "# Factor Dummies\n",
    "for word in commonwords:\n",
    "    X_train[str(word)] = X_train['review'].str.contains(str(word), case=False)\n",
    "    X_test[str(word)] = X_test['review'].str.contains(str(word), case=False)\n",
    "\n",
    "# Estimate model and test on our test sample\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train[commonwords], y_train)\n",
    "y_pred = bnb.predict(X_test[commonwords])\n",
    "y_pred_train = bnb.predict(X_train[commonwords])\n",
    "print_results(y_test, y_pred, y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model using the top 100 most common review words was slightly less accurate, at 66.5%. We got better at identifying negative reviews, but lost some of our accuracy we had for predicting positive reviews. We'll try again with the top 400 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------     Results     ---------------\n",
      "\n",
      "---------------  Training Data  ---------------\n",
      "\n",
      "Accuracy: \t84.8%\n",
      "Sensitivity: \t87.8%\n",
      "Specificity: \t81.7%\n",
      "\n",
      "---------------   Out of Sample ---------------\n",
      "\n",
      "Accuracy: \t73.0%\n",
      "Sensitivity: \t82.7%\n",
      "Specificity: \t63.7%\n",
      "\n",
      "----------------Confusion Matrix---------------\n",
      "\n",
      "                      Predicted Value\n",
      "\t\t |  Positive | Negative  |\n",
      "\t\t  -----------------------\n",
      "Actual \t|Positive|\t65   |    37\t |\n",
      "Value    --------------------------------\n",
      "\t|Negative|\t17   |    81\t |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove factors from previous model\n",
    "X_train = pd.DataFrame(X_train['review'])\n",
    "X_test = pd.DataFrame(X_test['review'])\n",
    "\n",
    "# List of 400 most common words\n",
    "commonwords = list(pd.Series(allwords).value_counts().index[:400])\n",
    "\n",
    "# Create factor dummies\n",
    "for word in commonwords:\n",
    "    X_train[str(word)] = X_train['review'].str.contains(str(word), case=False)\n",
    "    X_test[str(word)] = X_test['review'].str.contains(str(word), case=False)\n",
    "\n",
    "# Estimate and predict\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train[commonwords], y_train)\n",
    "y_pred = bnb.predict(X_test[commonwords])\n",
    "y_pred_train = bnb.predict(X_train[commonwords])\n",
    "print_results(y_test, y_pred, y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We increased our ability to detect negative reviews, without affecting our ability to detect positive ones. We have a fairly steep drop in accuracy and the associated measurements as we go from training data to testing. This should alert us to the possibility that our model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having a column named 'review' was giving us trouble. When a review with the word \"review\" was encountered,\n",
    "# the column containing our reviews would be replaced with a boolean type category. The columns are renamed\n",
    "# \"og_review,\" from here onward to resolve this issue\n",
    "\n",
    "X_train.rename(columns={'review': 'og_review'}, inplace=True)\n",
    "X_test.rename(columns={'review': 'og_review'}, inplace=True)\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(X_train['og_review'])\n",
    "X_test = pd.DataFrame(X_test['og_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which words are most correlated with either sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1)\n",
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create factor dummies for every word in our training data set\n",
    "for word in np.unique(allwords):\n",
    "    try:\n",
    "        X_train[str(word)] = X_train['og_review'].str.contains(str(word), case=False)\n",
    "    except:\n",
    "        errors.append(word)\n",
    "\n",
    "# List of correlation coefficients between factors and target variable\n",
    "corr_df = pd.concat([y_train, X_train], axis=1)\n",
    "corr_list = corr_df.corr().iloc[0,:]\n",
    "\n",
    "# List of the 25 words most positively and negatively correlated with target variable\n",
    "corr_words = list(corr_list.nlargest(26)[1:].index)\n",
    "corr_words += list(corr_list.nsmallest(25).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------     Results     ---------------\n",
      "\n",
      "---------------  Training Data  ---------------\n",
      "\n",
      "Accuracy: \t76.9%\n",
      "Sensitivity: \t81.8%\n",
      "Specificity: \t71.9%\n",
      "\n",
      "---------------   Out of Sample ---------------\n",
      "\n",
      "Accuracy: \t69.0%\n",
      "Sensitivity: \t77.6%\n",
      "Specificity: \t60.8%\n",
      "\n",
      "----------------Confusion Matrix---------------\n",
      "\n",
      "                      Predicted Value\n",
      "\t\t |  Positive | Negative  |\n",
      "\t\t  -----------------------\n",
      "Actual \t|Positive|\t62   |    40\t |\n",
      "Value    --------------------------------\n",
      "\t|Negative|\t22   |    76\t |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove factors from previous model\n",
    "X_train = pd.DataFrame(X_train['og_review'])\n",
    "X_test = pd.DataFrame(X_test['og_review'])\n",
    "\n",
    "# Create factor dummies\n",
    "for word in corr_words:\n",
    "    X_train[str(word)] = X_train['og_review'].str.contains(str(word), case=False)\n",
    "    X_test[str(word)] = X_test['og_review'].str.contains(str(word), case=False)\n",
    "\n",
    "# Estimate and predict\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train[corr_words], y_train)\n",
    "y_pred = bnb.predict(X_test[corr_words])\n",
    "y_pred_train = bnb.predict(X_train[corr_words])\n",
    "print_results(y_test, y_pred, y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible a word could be highly correlated with our target but not very common in our data set. Our model would be overly sensitive to the word or words that fit this description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list of words that are highly correlated with our target and in the list of top 400 words\n",
    "# List was adjusted to have roughly the same number of factors as the last model\n",
    "corr_words = list(corr_list.nlargest(36)[1:].index) + list(corr_list.nsmallest(35).index)\n",
    "corr_common_words = list(set(corr_words) & set(commonwords))\n",
    "len(corr_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------     Results     ---------------\n",
      "\n",
      "---------------  Training Data  ---------------\n",
      "\n",
      "Accuracy: \t78.6%\n",
      "Sensitivity: \t83.3%\n",
      "Specificity: \t73.9%\n",
      "\n",
      "---------------   Out of Sample ---------------\n",
      "\n",
      "Accuracy: \t70.0%\n",
      "Sensitivity: \t77.6%\n",
      "Specificity: \t62.7%\n",
      "\n",
      "----------------Confusion Matrix---------------\n",
      "\n",
      "                      Predicted Value\n",
      "\t\t |  Positive | Negative  |\n",
      "\t\t  -----------------------\n",
      "Actual \t|Positive|\t64   |    38\t |\n",
      "Value    --------------------------------\n",
      "\t|Negative|\t22   |    76\t |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove factors from previous model\n",
    "X_train = pd.DataFrame(X_train['og_review'])\n",
    "X_test = pd.DataFrame(X_test['og_review'])\n",
    "\n",
    "# Create factor dummies\n",
    "for word in corr_common_words:\n",
    "    X_train[str(word)] = X_train['og_review'].str.contains(str(word), case=False)\n",
    "    X_test[str(word)] = X_test['og_review'].str.contains(str(word), case=False)\n",
    "\n",
    "# Estimate and predict\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train[corr_common_words], y_train)\n",
    "y_pred = bnb.predict(X_test[corr_common_words])\n",
    "y_pred_train = bnb.predict(X_train[corr_common_words])\n",
    "print_results(y_test, y_pred, y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Very slightly more accurate. Let's use the same logic but expand our number of factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model from top 100 words most positively and negatively correlated with our target, \n",
    "# that are also in the top 400 words\n",
    "corr_words = list(corr_list.nlargest(101)[1:].index) + list(corr_list.nsmallest(100).index)\n",
    "corr_common_words = list(set(corr_words) & set(commonwords))\n",
    "len(corr_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------     Results     ---------------\n",
      "\n",
      "---------------  Training Data  ---------------\n",
      "\n",
      "Accuracy: \t85.5%\n",
      "Sensitivity: \t88.6%\n",
      "Specificity: \t82.4%\n",
      "\n",
      "---------------   Out of Sample ---------------\n",
      "\n",
      "Accuracy: \t73.0%\n",
      "Sensitivity: \t78.6%\n",
      "Specificity: \t67.6%\n",
      "\n",
      "----------------Confusion Matrix---------------\n",
      "\n",
      "                      Predicted Value\n",
      "\t\t |  Positive | Negative  |\n",
      "\t\t  -----------------------\n",
      "Actual \t|Positive|\t69   |    33\t |\n",
      "Value    --------------------------------\n",
      "\t|Negative|\t21   |    77\t |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove factors from previous model\n",
    "X_train = pd.DataFrame(X_train['og_review'])\n",
    "X_test = pd.DataFrame(X_test['og_review'])\n",
    "\n",
    "# Create factor dummies\n",
    "for word in corr_common_words:\n",
    "    X_train[str(word)] = X_train['og_review'].str.contains(str(word), case=False)\n",
    "    X_test[str(word)] = X_test['og_review'].str.contains(str(word), case=False)\n",
    "\n",
    "# Estimate and predict\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train[corr_common_words], y_train)\n",
    "y_pred = bnb.predict(X_test[corr_common_words])\n",
    "y_pred_train = bnb.predict(X_train[corr_common_words])\n",
    "print_results(y_test, y_pred, y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar accuracy to our model with the top 400 words, with approximately 1/3 of the factors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
