{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_path = 'textdata/yelp_labelled.txt'\n",
    "yelp_raw = pd.read_csv(yelp_path, delimiter='\\t', header=None)\n",
    "yelp_raw.columns = ['review', 'positive']\n",
    "yelp_raw.head()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(yelp_raw['review'], yelp_raw['positive'], test_size = 0.2, random_state=20)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "X_train_reset = X_train\n",
    "X_test_reset = X_test\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['good', 'great', 'bad', 'awful', 'not', 'angry', 'happy', 'glad', 'thrilled', 'sucks', 'recommend', 'wow', 'love', 'hate', 'nasty', 'service', 'food', 'atmosphere', 'loud', 'delicious', 'tasty', 'gross']\n",
    "for word in words:\n",
    "    X_train[str(word)] = X_train['review'].str.contains(str(word), case=False)\n",
    "    X_test[str(word)] = X_test['review'].str.contains(str(word), case=False)\n",
    "    \n",
    "def print_results(y_test, y_pred, y_train, y_train_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = (y_test == y_pred).sum()/len(y_test)\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    accuracy_train = (y_train == y_train_pred).sum()/len(y_train)\n",
    "    print('---------------     Results     ---------------\\n')\n",
    "    print('---------------  Training Data  ---------------\\n')\n",
    "    print('Accuracy: \\t{}%'.format(round(accuracy_train*100,1)))\n",
    "    print('Sensitivity: \\t{}%'.format(round(cm_train[1][1]*100/sum(cm_train[1]),1)))\n",
    "    print('Specificity: \\t{}%\\n'.format(round(cm_train[0][0]*100/sum(cm_train[0]),1)))\n",
    "    print('---------------   Out of Sample ---------------\\n')\n",
    "    print('Accuracy: \\t{}%'.format(round(accuracy*100,1)))\n",
    "    print('Sensitivity: \\t{}%'.format(round(cm[1][1]*100/sum(cm[1]),1)))\n",
    "    print('Specificity: \\t{}%'.format(round(cm[0][0]*100/sum(cm[0]),1)))\n",
    "    print('\\n----------------Confusion Matrix---------------\\n')\n",
    "    print('                      Predicted Value')\n",
    "    print('\\t\\t |  Positive | Negative  |')\n",
    "    print('\\t\\t  -----------------------')\n",
    "    print('Actual \\t|Positive|\\t{}   |    {}\\t |'.format(cm[0][0], cm[0][1]))\n",
    "    print('Value    --------------------------------')\n",
    "    print('\\t|Negative|\\t{}   |    {}\\t |'.format(cm[1][0], cm[1][1]))\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------     Results     ---------------\n",
      "\n",
      "---------------  Training Data  ---------------\n",
      "\n",
      "Accuracy: \t66.5%\n",
      "Sensitivity: \t43.8%\n",
      "Specificity: \t89.4%\n",
      "\n",
      "---------------   Out of Sample ---------------\n",
      "\n",
      "Accuracy: \t71.0%\n",
      "Sensitivity: \t48.0%\n",
      "Specificity: \t93.1%\n",
      "\n",
      "----------------Confusion Matrix---------------\n",
      "\n",
      "                      Predicted Value\n",
      "\t\t |  Positive | Negative  |\n",
      "\t\t  -----------------------\n",
      "Actual \t|Positive|\t95   |    7\t |\n",
      "Value    --------------------------------\n",
      "\t|Negative|\t51   |    47\t |\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(X_train[words], y_train)\n",
    "\n",
    "y_pred = bnb.predict(X_test[words])\n",
    "\n",
    "y_pred_train = bnb.predict(X_train[words])\n",
    "\n",
    "print_results(y_test, y_pred, y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model is accurate 71% of the time on a test sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords = []\n",
    "\n",
    "for review in X_train.review:\n",
    "    review = review.lower()\n",
    "    review = review.replace('.','').replace('!','').replace(',','').replace('?','').replace(':','').replace(';','')\n",
    "    review = review.replace('\"','').replace(\"'\",'').replace('-','').replace('(','').replace(')','').replace('&','and')\n",
    "    review = review.replace('$','').replace(\"%\",'').replace('*','').replace('+','').replace('/','')\n",
    "    allwords += review.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonwords = list(pd.Series(allwords).value_counts().index[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train['review'])\n",
    "X_test = pd.DataFrame(X_test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------     Results     ---------------\n",
      "\n",
      "---------------  Training Data  ---------------\n",
      "\n",
      "Accuracy: \t75.2%\n",
      "Sensitivity: \t78.1%\n",
      "Specificity: \t72.4%\n",
      "\n",
      "---------------   Out of Sample ---------------\n",
      "\n",
      "Accuracy: \t66.5%\n",
      "Sensitivity: \t71.4%\n",
      "Specificity: \t61.8%\n",
      "\n",
      "----------------Confusion Matrix---------------\n",
      "\n",
      "                      Predicted Value\n",
      "\t\t |  Positive | Negative  |\n",
      "\t\t  -----------------------\n",
      "Actual \t|Positive|\t63   |    39\t |\n",
      "Value    --------------------------------\n",
      "\t|Negative|\t28   |    70\t |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word in commonwords:\n",
    "    X_train[str(word)] = X_train['review'].str.contains(str(word), case=False)\n",
    "    X_test[str(word)] = X_test['review'].str.contains(str(word), case=False)\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(X_train[commonwords], y_train)\n",
    "\n",
    "y_pred = bnb.predict(X_test[commonwords])\n",
    "\n",
    "y_pred_train = bnb.predict(X_train[commonwords])\n",
    "\n",
    "print_results(y_test, y_pred, y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model using the top 100 most common review words was slightly less accurate, at 66.5%. We got better at identifying negative reviews, but lost some of our accuracy we had for predicting positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train['review'])\n",
    "X_test = pd.DataFrame(X_test['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------     Results     ---------------\n",
      "\n",
      "---------------  Training Data  ---------------\n",
      "\n",
      "Accuracy: \t84.2%\n",
      "Sensitivity: \t88.1%\n",
      "Specificity: \t80.4%\n",
      "\n",
      "---------------   Out of Sample ---------------\n",
      "\n",
      "Accuracy: \t73.0%\n",
      "Sensitivity: \t81.6%\n",
      "Specificity: \t64.7%\n",
      "\n",
      "----------------Confusion Matrix---------------\n",
      "\n",
      "                      Predicted Value\n",
      "\t\t |  Positive | Negative  |\n",
      "\t\t  -----------------------\n",
      "Actual \t|Positive|\t66   |    36\t |\n",
      "Value    --------------------------------\n",
      "\t|Negative|\t18   |    80\t |\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commonwords = list(pd.Series(allwords).value_counts().index[:400])\n",
    "\n",
    "for word in commonwords:\n",
    "    X_train[str(word)] = X_train['review'].str.contains(str(word), case=False)\n",
    "    X_test[str(word)] = X_test['review'].str.contains(str(word), case=False)\n",
    "\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "bnb.fit(X_train[commonwords], y_train)\n",
    "\n",
    "y_pred = bnb.predict(X_test[commonwords])\n",
    "\n",
    "y_pred_train = bnb.predict(X_train[commonwords])\n",
    "\n",
    "print_results(y_test, y_pred, y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We increased our ability to detect negative reviews, without affecting our ability to detect positive ones. We have a fairly steep drop in accuracy and the associated measurements as we go from training data to testing. This should alert us to the possibility that our model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having a column named 'review' was giving us trouble. When a review with the word \"review\" was encountered,\n",
    "# the column containing our reviews would be replaced with a boolean type category. The columns are renamed\n",
    "# \"og_review,\" from here onward to resolve this issue\n",
    "\n",
    "X_train.rename(columns={'review': 'og_review'}, inplace=True)\n",
    "X_test.rename(columns={'review': 'og_review'}, inplace=True)\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(X_train['og_review'])\n",
    "X_test = pd.DataFrame(X_test['og_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find which words are most correlated with either sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1)\n",
      "(1000, 2081)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "\n",
    "X_train.rename(columns={'review': 'og_review'}, inplace=True)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for word in np.unique(allwords):\n",
    "    try:\n",
    "        X_train[str(word)] = X_train['og_review'].str.contains(str(word), case=False)\n",
    "    except:\n",
    "        errors.append(word)\n",
    "    \n",
    "print(yelp_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['positive', '1', '10', '100', '1199', '12', '15', '15lb', '2', '20'], dtype='object')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_df = pd.concat([y_train, X_train], axis=1)\n",
    "corr_list = corr_df.corr().iloc[0,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "great        0.257740\n",
       "good         0.161075\n",
       "del          0.160331\n",
       "nice         0.143316\n",
       "eat          0.140505\n",
       "delicious    0.137543\n",
       "amazing      0.132095\n",
       "az           0.131020\n",
       "friendly     0.131020\n",
       "perfect      0.117486\n",
       "love         0.117446\n",
       "fantastic    0.111948\n",
       "friend       0.110485\n",
       "fan          0.108110\n",
       "ice          0.106928\n",
       "awesome      0.106136\n",
       "excellent    0.106136\n",
       "loved        0.106136\n",
       "an           0.105550\n",
       "Name: positive, dtype: float64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_list.nlargest(20)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no         -0.271282\n",
       "not        -0.270048\n",
       "do         -0.150424\n",
       "bad        -0.134129\n",
       "her        -0.133954\n",
       "minutes    -0.129168\n",
       "or         -0.128560\n",
       "too        -0.118099\n",
       "got        -0.115063\n",
       "min        -0.113706\n",
       "terrible   -0.113073\n",
       "3          -0.109395\n",
       "being      -0.109395\n",
       "much       -0.109395\n",
       "other      -0.108663\n",
       "ok         -0.107893\n",
       "nut        -0.107500\n",
       "bus        -0.107202\n",
       "would      -0.106261\n",
       "worst      -0.103455\n",
       "Name: positive, dtype: float64"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_list.nsmallest(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
